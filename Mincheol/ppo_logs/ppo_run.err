/scratch/user/mincheolseong/.conda/envs/grpo/lib/python3.10/site-packages/accelerate/accelerator.py:371: UserWarning: `log_with=tensorboard` was passed but no supported trackers are currently installed.
  warnings.warn(f"`log_with={log_with}` was passed but no supported trackers are currently installed.")
/scratch/user/mincheolseong/.conda/envs/grpo/lib/python3.10/site-packages/trl/trainer/ppo_trainer.py:1133: UserWarning: KL divergence is starting to become negative: -2.66 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.
  warnings.warn(
/scratch/user/mincheolseong/.conda/envs/grpo/lib/python3.10/site-packages/trl/trainer/ppo_trainer.py:1133: UserWarning: KL divergence is starting to become negative: -4.43 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.
  warnings.warn(
/scratch/user/mincheolseong/.conda/envs/grpo/lib/python3.10/site-packages/trl/trainer/ppo_trainer.py:1067: UserWarning: The average ratio of batch (60.22) exceeds threshold 20.00. Skipping batch.
  warnings.warn(
/scratch/user/mincheolseong/.conda/envs/grpo/lib/python3.10/site-packages/trl/trainer/ppo_trainer.py:1067: UserWarning: The average ratio of batch (66.76) exceeds threshold 20.00. Skipping batch.
  warnings.warn(
/scratch/user/mincheolseong/.conda/envs/grpo/lib/python3.10/site-packages/trl/trainer/ppo_trainer.py:1067: UserWarning: The average ratio of batch (110.04) exceeds threshold 20.00. Skipping batch.
  warnings.warn(
/scratch/user/mincheolseong/.conda/envs/grpo/lib/python3.10/site-packages/trl/trainer/ppo_trainer.py:1133: UserWarning: KL divergence is starting to become negative: -5.04 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.
  warnings.warn(
/scratch/user/mincheolseong/.conda/envs/grpo/lib/python3.10/site-packages/trl/trainer/ppo_trainer.py:1133: UserWarning: KL divergence is starting to become negative: -5.42 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.
  warnings.warn(
/scratch/user/mincheolseong/.conda/envs/grpo/lib/python3.10/site-packages/trl/trainer/ppo_trainer.py:1133: UserWarning: KL divergence is starting to become negative: -9.20 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.
  warnings.warn(
/scratch/user/mincheolseong/.conda/envs/grpo/lib/python3.10/site-packages/trl/trainer/ppo_trainer.py:1133: UserWarning: KL divergence is starting to become negative: -1.29 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.
  warnings.warn(
/scratch/user/mincheolseong/.conda/envs/grpo/lib/python3.10/site-packages/trl/trainer/ppo_trainer.py:1133: UserWarning: KL divergence is starting to become negative: -2.44 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.
  warnings.warn(
/scratch/user/mincheolseong/.conda/envs/grpo/lib/python3.10/site-packages/trl/trainer/ppo_trainer.py:1133: UserWarning: KL divergence is starting to become negative: -1.66 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.
  warnings.warn(
/scratch/user/mincheolseong/.conda/envs/grpo/lib/python3.10/site-packages/trl/trainer/ppo_trainer.py:1133: UserWarning: KL divergence is starting to become negative: -10.18 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.
  warnings.warn(
/scratch/user/mincheolseong/.conda/envs/grpo/lib/python3.10/site-packages/trl/trainer/ppo_trainer.py:1133: UserWarning: KL divergence is starting to become negative: -15.27 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.
  warnings.warn(
/scratch/user/mincheolseong/.conda/envs/grpo/lib/python3.10/site-packages/trl/trainer/ppo_trainer.py:1133: UserWarning: KL divergence is starting to become negative: -11.78 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.
  warnings.warn(
/scratch/user/mincheolseong/.conda/envs/grpo/lib/python3.10/site-packages/trl/trainer/ppo_trainer.py:1133: UserWarning: KL divergence is starting to become negative: -3.03 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.
  warnings.warn(
/scratch/user/mincheolseong/.conda/envs/grpo/lib/python3.10/site-packages/trl/trainer/ppo_trainer.py:1067: UserWarning: The average ratio of batch (48.90) exceeds threshold 20.00. Skipping batch.
  warnings.warn(
/scratch/user/mincheolseong/.conda/envs/grpo/lib/python3.10/site-packages/trl/trainer/ppo_trainer.py:1133: UserWarning: KL divergence is starting to become negative: -14.89 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.
  warnings.warn(
/scratch/user/mincheolseong/.conda/envs/grpo/lib/python3.10/site-packages/trl/trainer/ppo_trainer.py:1133: UserWarning: KL divergence is starting to become negative: -21.10 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.
  warnings.warn(
/scratch/user/mincheolseong/.conda/envs/grpo/lib/python3.10/site-packages/trl/trainer/ppo_trainer.py:1133: UserWarning: KL divergence is starting to become negative: -18.76 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.
  warnings.warn(
/scratch/user/mincheolseong/.conda/envs/grpo/lib/python3.10/site-packages/trl/trainer/ppo_trainer.py:1067: UserWarning: The average ratio of batch (56.31) exceeds threshold 20.00. Skipping batch.
  warnings.warn(
/scratch/user/mincheolseong/.conda/envs/grpo/lib/python3.10/site-packages/trl/trainer/ppo_trainer.py:1067: UserWarning: The average ratio of batch (210.00) exceeds threshold 20.00. Skipping batch.
  warnings.warn(
/scratch/user/mincheolseong/.conda/envs/grpo/lib/python3.10/site-packages/trl/trainer/ppo_trainer.py:1133: UserWarning: KL divergence is starting to become negative: -3.44 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.
  warnings.warn(
/scratch/user/mincheolseong/.conda/envs/grpo/lib/python3.10/site-packages/trl/trainer/ppo_trainer.py:1133: UserWarning: KL divergence is starting to become negative: -4.97 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.
  warnings.warn(
/scratch/user/mincheolseong/.conda/envs/grpo/lib/python3.10/site-packages/trl/trainer/ppo_trainer.py:1133: UserWarning: KL divergence is starting to become negative: -10.08 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.
  warnings.warn(
/scratch/user/mincheolseong/.conda/envs/grpo/lib/python3.10/site-packages/trl/trainer/ppo_trainer.py:1133: UserWarning: KL divergence is starting to become negative: -7.89 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.
  warnings.warn(
/scratch/user/mincheolseong/.conda/envs/grpo/lib/python3.10/site-packages/trl/trainer/ppo_trainer.py:1133: UserWarning: KL divergence is starting to become negative: -8.55 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.
  warnings.warn(
/scratch/user/mincheolseong/.conda/envs/grpo/lib/python3.10/site-packages/trl/trainer/ppo_trainer.py:1133: UserWarning: KL divergence is starting to become negative: -13.39 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.
  warnings.warn(
/scratch/user/mincheolseong/.conda/envs/grpo/lib/python3.10/site-packages/trl/trainer/ppo_trainer.py:1133: UserWarning: KL divergence is starting to become negative: -11.71 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.
  warnings.warn(
/scratch/user/mincheolseong/.conda/envs/grpo/lib/python3.10/site-packages/trl/trainer/ppo_trainer.py:1133: UserWarning: KL divergence is starting to become negative: -15.82 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.
  warnings.warn(
/scratch/user/mincheolseong/.conda/envs/grpo/lib/python3.10/site-packages/trl/trainer/ppo_trainer.py:1133: UserWarning: KL divergence is starting to become negative: -1.05 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.
  warnings.warn(
/scratch/user/mincheolseong/.conda/envs/grpo/lib/python3.10/site-packages/trl/trainer/ppo_trainer.py:1133: UserWarning: KL divergence is starting to become negative: -14.48 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.
  warnings.warn(
/scratch/user/mincheolseong/.conda/envs/grpo/lib/python3.10/site-packages/trl/trainer/ppo_trainer.py:1133: UserWarning: KL divergence is starting to become negative: -7.87 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.
  warnings.warn(
/scratch/user/mincheolseong/.conda/envs/grpo/lib/python3.10/site-packages/trl/trainer/ppo_trainer.py:1133: UserWarning: KL divergence is starting to become negative: -11.86 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.
  warnings.warn(
/scratch/user/mincheolseong/.conda/envs/grpo/lib/python3.10/site-packages/trl/trainer/ppo_trainer.py:1133: UserWarning: KL divergence is starting to become negative: -7.46 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.
  warnings.warn(
/scratch/user/mincheolseong/.conda/envs/grpo/lib/python3.10/site-packages/trl/trainer/ppo_trainer.py:1133: UserWarning: KL divergence is starting to become negative: -5.03 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.
  warnings.warn(
/scratch/user/mincheolseong/.conda/envs/grpo/lib/python3.10/site-packages/trl/trainer/ppo_trainer.py:1133: UserWarning: KL divergence is starting to become negative: -7.21 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.
  warnings.warn(
/scratch/user/mincheolseong/.conda/envs/grpo/lib/python3.10/site-packages/trl/trainer/ppo_trainer.py:1133: UserWarning: KL divergence is starting to become negative: -7.62 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.
  warnings.warn(
/scratch/user/mincheolseong/.conda/envs/grpo/lib/python3.10/site-packages/trl/trainer/ppo_trainer.py:1133: UserWarning: KL divergence is starting to become negative: -14.33 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.
  warnings.warn(
/scratch/user/mincheolseong/.conda/envs/grpo/lib/python3.10/site-packages/trl/trainer/ppo_trainer.py:1133: UserWarning: KL divergence is starting to become negative: -10.79 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.
  warnings.warn(
/scratch/user/mincheolseong/.conda/envs/grpo/lib/python3.10/site-packages/trl/trainer/ppo_trainer.py:1133: UserWarning: KL divergence is starting to become negative: -12.78 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.
  warnings.warn(
/scratch/user/mincheolseong/.conda/envs/grpo/lib/python3.10/site-packages/trl/trainer/ppo_trainer.py:1133: UserWarning: KL divergence is starting to become negative: -14.03 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.
  warnings.warn(
/scratch/user/mincheolseong/.conda/envs/grpo/lib/python3.10/site-packages/trl/trainer/ppo_trainer.py:1133: UserWarning: KL divergence is starting to become negative: -13.81 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.
  warnings.warn(
/scratch/user/mincheolseong/.conda/envs/grpo/lib/python3.10/site-packages/trl/trainer/ppo_trainer.py:1133: UserWarning: KL divergence is starting to become negative: -2.31 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.
  warnings.warn(
/scratch/user/mincheolseong/.conda/envs/grpo/lib/python3.10/site-packages/trl/trainer/ppo_trainer.py:1133: UserWarning: KL divergence is starting to become negative: -10.88 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.
  warnings.warn(
/scratch/user/mincheolseong/.conda/envs/grpo/lib/python3.10/site-packages/trl/trainer/ppo_trainer.py:1133: UserWarning: KL divergence is starting to become negative: -10.31 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.
  warnings.warn(
/scratch/user/mincheolseong/.conda/envs/grpo/lib/python3.10/site-packages/trl/trainer/ppo_trainer.py:1133: UserWarning: KL divergence is starting to become negative: -11.25 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.
  warnings.warn(
/scratch/user/mincheolseong/.conda/envs/grpo/lib/python3.10/site-packages/trl/trainer/ppo_trainer.py:1133: UserWarning: KL divergence is starting to become negative: -13.91 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.
  warnings.warn(
/scratch/user/mincheolseong/.conda/envs/grpo/lib/python3.10/site-packages/trl/trainer/ppo_trainer.py:1133: UserWarning: KL divergence is starting to become negative: -20.59 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.
  warnings.warn(
/scratch/user/mincheolseong/.conda/envs/grpo/lib/python3.10/site-packages/trl/trainer/ppo_trainer.py:1133: UserWarning: KL divergence is starting to become negative: -12.94 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.
  warnings.warn(
/scratch/user/mincheolseong/.conda/envs/grpo/lib/python3.10/site-packages/trl/trainer/ppo_trainer.py:1133: UserWarning: KL divergence is starting to become negative: -15.18 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.
  warnings.warn(
/scratch/user/mincheolseong/.conda/envs/grpo/lib/python3.10/site-packages/trl/trainer/ppo_trainer.py:1133: UserWarning: KL divergence is starting to become negative: -13.32 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.
  warnings.warn(
/scratch/user/mincheolseong/.conda/envs/grpo/lib/python3.10/site-packages/trl/trainer/ppo_trainer.py:1133: UserWarning: KL divergence is starting to become negative: -14.80 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.
  warnings.warn(
/scratch/user/mincheolseong/.conda/envs/grpo/lib/python3.10/site-packages/trl/trainer/ppo_trainer.py:1133: UserWarning: KL divergence is starting to become negative: -25.95 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.
  warnings.warn(
/scratch/user/mincheolseong/.conda/envs/grpo/lib/python3.10/site-packages/trl/trainer/ppo_trainer.py:1133: UserWarning: KL divergence is starting to become negative: -27.59 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.
  warnings.warn(
/scratch/user/mincheolseong/.conda/envs/grpo/lib/python3.10/site-packages/trl/trainer/ppo_trainer.py:1133: UserWarning: KL divergence is starting to become negative: -21.15 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.
  warnings.warn(
/scratch/user/mincheolseong/.conda/envs/grpo/lib/python3.10/site-packages/trl/trainer/ppo_trainer.py:1133: UserWarning: KL divergence is starting to become negative: -12.88 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.
  warnings.warn(
/scratch/user/mincheolseong/.conda/envs/grpo/lib/python3.10/site-packages/trl/trainer/ppo_trainer.py:1133: UserWarning: KL divergence is starting to become negative: -20.09 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.
  warnings.warn(
/scratch/user/mincheolseong/.conda/envs/grpo/lib/python3.10/site-packages/trl/trainer/ppo_trainer.py:1133: UserWarning: KL divergence is starting to become negative: -19.96 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.
  warnings.warn(
/scratch/user/mincheolseong/.conda/envs/grpo/lib/python3.10/site-packages/trl/trainer/ppo_trainer.py:1067: UserWarning: The average ratio of batch (46.18) exceeds threshold 20.00. Skipping batch.
  warnings.warn(
/scratch/user/mincheolseong/.conda/envs/grpo/lib/python3.10/site-packages/trl/trainer/ppo_trainer.py:1067: UserWarning: The average ratio of batch (57.21) exceeds threshold 20.00. Skipping batch.
  warnings.warn(
/scratch/user/mincheolseong/.conda/envs/grpo/lib/python3.10/site-packages/trl/trainer/ppo_trainer.py:1133: UserWarning: KL divergence is starting to become negative: -13.67 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.
  warnings.warn(
/scratch/user/mincheolseong/.conda/envs/grpo/lib/python3.10/site-packages/trl/trainer/ppo_trainer.py:1133: UserWarning: KL divergence is starting to become negative: -12.89 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.
  warnings.warn(
